{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c3ce418-1eca-4bd6-8ea9-a84fb69105eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d0b758e-4849-4bdf-882b-4b2718808307",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e541156d-bbdc-41d6-b30c-a95ba75de8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"C:/Users/91727/OneDrive/Desktop/dts/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b653ca10-2be5-46d2-a80f-acb06f9eed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de976fd8-52b9-46b3-903d-ef1659bc21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landmarks1(image):\n",
    "    # Convert the BGR image to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the image and extract landmarks\n",
    "    results = face_mesh.process(image_rgb)\n",
    "    \n",
    "    # Check if landmarks are detected\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Flatten x, y, z coordinates into a single list\n",
    "            flattened_landmarks = []\n",
    "            for landmark in face_landmarks.landmark:\n",
    "                flattened_landmarks.extend([landmark.x, landmark.y, landmark.z])  # Append x, y, z coordinates\n",
    "\n",
    "            return flattened_landmarks\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7552751-0dc9-4b21-b505-7ce8248bc55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def extract_landmarks(image):\\n    # Convert the BGR image to RGB\\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\\n    \\n    # Process the image and extract landmarks\\n    results = face_mesh.process(image_rgb)\\n    \\n    # Check if landmarks are detected\\n    if results.multi_face_landmarks:\\n        for face_landmarks in results.multi_face_landmarks:\\n            # Extract x, y, z coordinates into lists\\n            xs = [landmark.x for landmark in face_landmarks.landmark]\\n            ys = [landmark.y for landmark in face_landmarks.landmark]\\n            zs = [landmark.z for landmark in face_landmarks.landmark]\\n            \\n            # Normalize x, y, and z coordinates\\n            min_x, min_y, min_z = min(xs), min(ys), min(zs)\\n            normalized_landmarks = []\\n\\n            for x, y, z in zip(xs, ys, zs):\\n                normalized_landmarks.append(x - min_x)  # Normalize x\\n                normalized_landmarks.append(y - min_y)  # Normalize y\\n                normalized_landmarks.append(z - min_z)  # Normalize z\\n\\n            return normalized_landmarks\\n\\n    return None'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_landmarks2(image):\n",
    "    # Convert the BGR image to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the image and extract landmarks\n",
    "    results = face_mesh.process(image_rgb)\n",
    "    \n",
    "    # Check if landmarks are detected\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Extract x, y, z coordinates into lists\n",
    "            xs = [landmark.x for landmark in face_landmarks.landmark]\n",
    "            ys = [landmark.y for landmark in face_landmarks.landmark]\n",
    "            zs = [landmark.z for landmark in face_landmarks.landmark]\n",
    "            \n",
    "            # Normalize x, y, and z coordinates\n",
    "            min_x, min_y, min_z = min(xs), min(ys), min(zs)\n",
    "            normalized_landmarks = []\n",
    "\n",
    "            for x, y, z in zip(xs, ys, zs):\n",
    "                normalized_landmarks.append(x - min_x)  # Normalize x\n",
    "                normalized_landmarks.append(y - min_y)  # Normalize y\n",
    "                normalized_landmarks.append(z - min_z)  # Normalize z\n",
    "\n",
    "            return normalized_landmarks\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "627d39cb-71a0-46b5-8f03-54b8077c56b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='google.protobuf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7ddfc56-bcdf-4f56-a12d-84828f275a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in [\"angry\", \"disgusted\", \"happy\", \"neutral\", \"sad\", \"surprised\"]:\n",
    "    category_path = os.path.join(base_dir, category)\n",
    "    \n",
    "    for image_file in os.listdir(category_path):\n",
    "        image_path = os.path.join(category_path, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Extract landmarks from the image\n",
    "        landmarks = extract_landmarks(image)\n",
    "        \n",
    "        if landmarks:\n",
    "            # Add the category and landmarks to the data list\n",
    "            landmarks_data.append({'category': category, 'landmarks': landmarks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3542601b-ef13-4061-b312-40a11f16c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_landmarks = pd.DataFrame(landmarks_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a2c3baa-8791-4e04-8a3f-0634c344c062",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_landmarks.to_csv('new_landmarks_nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea860d8-12aa-48c0-a24a-adab72c22070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaeb249-612d-4065-a32b-1bc8b8077e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
